{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1NrfEiTnlLS"
   },
   "source": [
    "폴더 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = '/app/HSK/FL_Seg'  # 파일 업로드한 경로 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "summary = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86ea40c7"
   },
   "source": [
    "### 필요한 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lRfwuEL2--n-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations==0.4.6 in /home/user/.local/lib/python3.8/site-packages (0.4.6)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.5.4)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (5.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.19.2)\n",
      "Requirement already satisfied: imageio in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.19.1)\n",
      "Requirement already satisfied: Shapely in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n",
      "Requirement already satisfied: Pillow in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.5.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (21.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2022.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.33.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yacs in /home/user/.local/lib/python3.8/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from yacs) (5.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations==0.4.6\n",
    "!pip install   yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "52bbfdfb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "649609b1"
   },
   "source": [
    "### 재구현 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c35eec19"
   },
   "outputs": [],
   "source": [
    "def init_seeds(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    if seed == 0:  # slower, more reproducible\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = False\n",
    "    else:  # faster, less reproducible\n",
    "        cudnn.deterministic = False\n",
    "        cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b90c4ec5"
   },
   "outputs": [],
   "source": [
    "init_seeds(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f8a343a"
   },
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "499b3f23"
   },
   "outputs": [],
   "source": [
    "rgb_path = os.path.join(workspace_path, 'data/train/rgb/')\n",
    "ngr_path = os.path.join(workspace_path, 'data/train/ngr/')\n",
    "label_path = os.path.join(workspace_path, 'data/train/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d4e26b49"
   },
   "outputs": [],
   "source": [
    "rgb_images = os.listdir(rgb_path)\n",
    "rgb_images = [os.path.join(rgb_path,x) for x in rgb_images]\n",
    "ngr_images = os.listdir(ngr_path)\n",
    "ngr_images = [os.path.join(ngr_path, x) for x in ngr_images]\n",
    "label_images = os.listdir(label_path)\n",
    "label_images = [os.path.join(label_path, x) for x in label_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997d5237"
   },
   "source": [
    "### 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ca96420c"
   },
   "outputs": [],
   "source": [
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, label_path, patch_size = 400, patch_stride = 100, is_train = True, cache_dir = './cache', transforms = None):\n",
    "        self.image_path = image_path\n",
    "        self.label_path = label_path\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_stride = patch_stride\n",
    "        self.is_train = is_train\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.patch_images = []\n",
    "        self.patch_labels = []\n",
    "        \n",
    "        \n",
    "        cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        if is_train:\n",
    "            for img_path in self.image_path:\n",
    "                img = cv2.imread(img_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'rgb_{os.path.splitext(os.path.basename(img_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_images.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "\n",
    "            for label_path in self.label_path:\n",
    "                img = cv2.imread(label_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'label_{os.path.splitext(os.path.basename(label_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_labels.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "        else:\n",
    "            self.patch_images = self.image_path\n",
    "            self.patch_labels = self.label_path\n",
    "    def __len__(self):\n",
    "        return len(self.patch_images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.patch_images[idx])\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = cv2.imread(self.patch_labels[idx])\n",
    "            # numpy arrays to tensors\n",
    "            h, w = label.shape[:2]\n",
    "        \n",
    "            target = np.zeros((h, w), dtype=np.uint8)\n",
    "            pos = np.where(np.all(label == [0, 0, 255], axis=-1))  # thick cloud\n",
    "            target[pos] = 1\n",
    "            pos = np.where(np.all(label == [0, 255, 0], axis=-1))  # thin cloud\n",
    "            target[pos] = 2\n",
    "            pos = np.where(np.all(label == [0, 255, 255], axis=-1))  # cloud shadow\n",
    "            target[pos] = 3\n",
    "        else:\n",
    "            target = None\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        if self.is_train:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, self.patch_images[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09d79e8b"
   },
   "source": [
    "### 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a6ac4eae"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 20\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "patch_size = 400\n",
    "patch_stride = 100\n",
    "num_workers = 0\n",
    "\n",
    "num_classes = 4\n",
    "class_names = ['thick cloud', 'thin cloud', 'cloud shadow']\n",
    "\n",
    "train_data_rate = 0.7\n",
    "\n",
    "model_name = 'dilated_unet'\n",
    "\n",
    "loss_func = 'dice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e4513b1"
   },
   "source": [
    "### 데이터증대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "17dc2c12"
   },
   "outputs": [],
   "source": [
    "class ImageAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.HorizontalFlip(p=0.5),\n",
    "                             A.VerticalFlip(p=0.5),\n",
    "                             A.ShiftScaleRotate(p=0.5),\n",
    "                             A.RandomBrightnessContrast(p=0.3),\n",
    "                             A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']\n",
    "\n",
    "class DefaultAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "03a59423"
   },
   "outputs": [],
   "source": [
    "train_transforms = ImageAug()\n",
    "val_transforms = DefaultAug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2147f462"
   },
   "source": [
    "### 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "98bed485"
   },
   "outputs": [],
   "source": [
    "#train dataset\n",
    "train_dataset = CloudDataset(rgb_images[:int(len(rgb_images)*train_data_rate)], label_images[:int(len(label_images)*train_data_rate)],\n",
    "                            transforms=train_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "#valid dataset\n",
    "val_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate):], label_images[int(len(label_images)*train_data_rate):],\n",
    "                            transforms=val_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cbab53"
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e54a2c7d"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eIK90NknzGPn"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DilatedConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation, padding):\n",
    "        super(DilatedConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, dilation=dilation),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConcatDoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConcatDoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((skip, x), dim=1)\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class MyDilatedConvUNet(nn.Module):\n",
    "    def __init__(self, filters=44, depth=3, bottleneck_depth=6):\n",
    "        super(MyDilatedConvUNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.encoder_path = nn.ModuleList()\n",
    "        src_in_channels = 3     # Geo-TIFF has four channels (R, G, B, and NIR)\n",
    "        for d in range(depth):\n",
    "            in_channels = src_in_channels if d == 0 else filters * 2 ** (d-1)\n",
    "            self.encoder_path.append(\n",
    "                DoubleConvBlock(in_channels, filters * 2 ** d))\n",
    "        self.maxpool = nn.MaxPool2d(2, 2, padding=0)\n",
    "        self.bottleneck_path = nn.ModuleList()\n",
    "        for d in range(bottleneck_depth):\n",
    "            in_channels = filters * 2 ** (depth - 1) if d == 0 else filters * 2 ** depth\n",
    "            self.bottleneck_path.append(DilatedConvBlock(in_channels, filters * 2 ** depth, 2 ** d, 2 ** d))\n",
    "        self.decoder_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.decoder_path.append(ConcatDoubleConvBlock(in_channels, filters * 2 ** (depth - d - 1)))\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.up_path.append(nn.ConvTranspose2d(in_channels, filters * 2 ** (depth - d - 1),\n",
    "                                                        kernel_size=4, stride=2, padding=1))\n",
    "        out_channels = 4     # output channels (num_classes + 1(background))\n",
    "        self.last_conv = nn.Conv2d(filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = []\n",
    "        for block in self.encoder_path:\n",
    "            x = block(x)\n",
    "            skip.append(x)\n",
    "            x = self.maxpool(x)\n",
    "        dilated = []\n",
    "        for block in self.bottleneck_path:\n",
    "            x = block(x)\n",
    "            dilated.append(x)\n",
    "        x = torch.stack(dilated, dim=-1).sum(dim=-1)  # sum over list\n",
    "\n",
    "        # up-sampling and double convolutions\n",
    "        for d in range(self.depth):\n",
    "            x = self.up_path[d](x)\n",
    "            x = self.decoder_path[d](x, skip[-(d+1)])\n",
    "\n",
    "        return self.last_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "78338b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  9083804\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "if model_name == 'deeplabv3':\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=4)\n",
    "\n",
    "elif model_name == 'dilated_unet':\n",
    "    model = MyDilatedConvUNet()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('number of parameters: ', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "467743f7"
   },
   "source": [
    "### Opimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "314acf1e"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuJfaks1zbtC"
   },
   "source": [
    "### 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "c124f5df"
   },
   "outputs": [],
   "source": [
    "def fitness_test(true, pred, num_classes=4):\n",
    "    eps = 1e-7\n",
    "    true_one_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_one_hot = true_one_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "    pred_max = pred.argmax(1)      # (B, C, H, W) to (B, H, W)\n",
    "    pix_acc = (true == pred_max.unsqueeze(1)).sum().float().div(true.nelement())\n",
    "    pred_one_hot = F.one_hot(pred_max, num_classes=num_classes)   # (B, H, W) to (B, H, W, C)\n",
    "    pred_one_hot = pred_one_hot.permute(0, 3, 1, 2)   # (B, H, W, C) to (B, C, H, W)\n",
    "\n",
    "    true_one_hot = true_one_hot.type(pred_one_hot.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))  # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(pred_one_hot & true_one_hot, dims)\n",
    "    union = torch.sum(pred_one_hot | true_one_hot, dims)\n",
    "    m_iou = (intersection / (union + eps)).mean()\n",
    "\n",
    "    return m_iou.item(), pix_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "v74FWycdzdev"
   },
   "outputs": [],
   "source": [
    "# Loss 함수 정의\n",
    "def ce_loss(true, logits, ignore=255):\n",
    "    \"\"\"Computes the weighted multi-class cross-entropy loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        ignore: the class index to ignore.\n",
    "    Returns:\n",
    "        ce_loss: the weighted multi-class cross-entropy loss.\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(\n",
    "        logits.float(),\n",
    "        true.squeeze(1).long(),    # [B, H, W]\n",
    "        ignore_index=ignore,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        # true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))        # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "def jaccard_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d1af165"
   },
   "source": [
    "### 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt(f_name, weights):\n",
    "    with open(f\"{f_name}.txt\", \"w\") as f:\n",
    "        for p in weights:\n",
    "            f.write(p + \"\\n\")\n",
    "            f.write(str(weights[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bad17d99"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=400, use_scheduler=False, save_path='./ckpt'):\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    if use_scheduler:\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "    start_epoch = 0\n",
    "    resume = True\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    weight_file = save_path + '/{}.pt'.format(model_name)\n",
    "\n",
    "    best_fit = 0.0\n",
    "    num_epochs = epochs\n",
    "\n",
    "    if resume:\n",
    "        if os.path.exists(weight_file):\n",
    "            checkpoint = torch.load(weight_file)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_fit = checkpoint['best_fit']\n",
    "            print(\"Starting training for %g epochs...\" % start_epoch)\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        # loss, metric = train_one_epoch(model, optimizer, dataloader, device, epoch)\n",
    "        t0 = time.time()\n",
    "        loss = train_one_epoch(model, optimizer, train_dataloader, loss_func, device, epoch, num_epochs)\n",
    "        t1 = time.time()\n",
    "        print('[Epoch %g] loss=%.4f, time=%.1f' % (epoch, loss.item(), t1 - t0))\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step(loss)\n",
    "        #tb_writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        state = {'model_name': model_name, 'epoch': epoch, 'best_fit': best_fit, 'model': model.state_dict()}\n",
    "        torch.save(state, weight_file)\n",
    "\n",
    "        #tb_writer.add_scalar('train_epoch_loss', loss, epoch)\n",
    "        \n",
    "        torch.save(state, save_path + '/{}_{}.pt'.format(model_name, epoch)) \n",
    "        \n",
    "        # validation\n",
    "        patch_size = patch_size\n",
    "        fit = val_one_epoch(model, val_dataloader, device, epoch, num_epochs, patch_size)\n",
    "        if fit > best_fit:\n",
    "            print(\"best fit so far=>saved\")\n",
    "            torch.save(state, save_path + '/{}_best.pt'.format(model_name))\n",
    "            best_fit = fit\n",
    "        torch.save(state, save_path + '/{}_.pt'.format(model_name))    \n",
    "#         writer.add_scalar('D_loss_adv', d_loss_adv.item(), epoch)\n",
    "#         writer.add_scalar('D_loss_cls', d_loss_cls.item(), epoch)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, loss_func, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    losses = np.array([])\n",
    "    metrics = np.array([])\n",
    "    bi0 = epoch * len(data_loader)  # batch index\n",
    "\n",
    "    print(('\\n' + '%10s' * 2) % ('Epoch', 'loss'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0)\n",
    "    pbar.set_description(s)\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        if model_name == 'deeplabv3':\n",
    "            preds = model(imgs)['out']\n",
    "            targets = targets.long()\n",
    "        elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "            preds = model(imgs)\n",
    "            h, w = preds.shape[2], preds.shape[3]\n",
    "            targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n",
    "        elif model_name == 'dilated_unet':\n",
    "            preds = model(imgs)\n",
    "            targets = targets.long()\n",
    "            \n",
    "        if loss_func == 'jaccard':\n",
    "            loss = jaccard_loss(targets, preds)\n",
    "        elif loss_func == 'dice':\n",
    "            loss = dice_loss(targets, preds)\n",
    "        elif loss_func == 'ce':\n",
    "            loss = ce_loss(targets, preds)\n",
    "        else:\n",
    "            print('unsupported loss function')\n",
    "            exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # cv2_imshow(imgs[0], preds[0])\n",
    "            losses = np.append(losses, loss.item())\n",
    "\n",
    "            s = ('%10s' + '%10.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), loss.item())\n",
    "            pbar.set_description(s)\n",
    "            bi = bi0 + i\n",
    "            #tb_writer.add_scalar('train_batch_loss', loss.item(), bi)\n",
    "\n",
    "    epoch_loss = losses.mean()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def val_one_epoch(model, data_loader, device, epoch, num_epochs, patch_size):\n",
    "    model.eval()\n",
    "    m_iou_list = np.array([])\n",
    "    pix_acc_list = np.array([])\n",
    "\n",
    "    print(('\\n' + '%10s' * 3) % ('Epoch(V)', 'mIOU', 'Accuracy'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0, 0.0)\n",
    "    pbar.set_description(s)\n",
    "\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            if model_name == 'deeplabv3':\n",
    "                preds = model(imgs)['out']\n",
    "                targets = targets.long()\n",
    "            elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "                preds = model(imgs)\n",
    "                h, w = preds.shape[2], preds.shape[3]\n",
    "                targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n",
    "            elif model_name == 'dilated_unet':\n",
    "                preds = model(imgs)\n",
    "                targets = targets.long()\n",
    "\n",
    "            m_iou, pix_acc = fitness_test(targets, preds)\n",
    "\n",
    "            s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), m_iou, pix_acc)\n",
    "            pbar.set_description(s)\n",
    "            m_iou_list = np.append(m_iou_list, m_iou)\n",
    "            pix_acc_list = np.append(pix_acc_list, pix_acc)\n",
    "    val_m_iou_mean = m_iou_list.mean()\n",
    "    val_pix_acc_mean = pix_acc_list.mean()\n",
    "    print('[V] mIOU={:.3f}, Accuracy={:.3f}'.format(val_m_iou_mean, val_pix_acc_mean))\n",
    "    #tb_writer.add_scalar('val_epoch_m_iou', val_m_iou_mean, epoch)\n",
    "    #tb_writer.add_scalar('val_epoch_pix_acc', val_pix_acc_mean, epoch)\n",
    "    return val_pix_acc_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "600d9790"
   },
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "b74e3dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.2732: 100%|████████| 3552/3552 [21:36<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] loss=0.2572, time=1296.7\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.5810   2.5399: 100%|█| 1525/1525 [05:16<00:00,  4.82it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.619, Accuracy=3.094\n",
      "best fit so far=>saved\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.3366: 100%|████████| 3552/3552 [21:12<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.2552, time=1272.3\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.5690   2.6673: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.611, Accuracy=2.998\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.1840: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.2517, time=1273.4\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.6446   3.3009: 100%|█| 1525/1525 [05:09<00:00,  4.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.618, Accuracy=2.991\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.2116: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.2494, time=1273.7\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.6661   2.7029: 100%|█| 1525/1525 [05:10<00:00,  4.91it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.612, Accuracy=2.957\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.2685: 100%|████████| 3552/3552 [21:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] loss=0.2475, time=1274.1\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.4241   3.1805: 100%|█| 1525/1525 [05:09<00:00,  4.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.626, Accuracy=2.966\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.2949: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] loss=0.2437, time=1273.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.6030   3.2621: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.612, Accuracy=2.934\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.1677: 100%|████████| 3552/3552 [21:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] loss=0.2433, time=1274.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.6871   2.3860: 100%|█| 1525/1525 [05:09<00:00,  4.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.623, Accuracy=3.027\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.2585: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] loss=0.2408, time=1273.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.6127   2.3813: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.638, Accuracy=3.064\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.1534: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] loss=0.2370, time=1273.1\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.5979   2.7079: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.625, Accuracy=2.995\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.2944: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] loss=0.2338, time=1273.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.7672   2.9954: 100%|█| 1525/1525 [05:10<00:00,  4.91it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.632, Accuracy=3.041\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.2409: 100%|████████| 3552/3552 [21:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss=0.2340, time=1274.8\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.5543   3.6236: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.635, Accuracy=2.979\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.3510: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] loss=0.2293, time=1273.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.6295   3.8426: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.617, Accuracy=3.025\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.1969: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] loss=0.2296, time=1273.1\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.5624   2.4345: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.619, Accuracy=3.080\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.2785: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] loss=0.2268, time=1273.5\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.6426   2.5774: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.632, Accuracy=2.999\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.1899: 100%|████████| 3552/3552 [21:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] loss=0.2265, time=1274.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.6423   3.9979: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.617, Accuracy=3.023\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.1667: 100%|████████| 3552/3552 [21:12<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] loss=0.2236, time=1272.6\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.6497   2.6623: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.635, Accuracy=2.996\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.2420: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] loss=0.2214, time=1273.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.7895   3.4067: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.637, Accuracy=3.011\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.3132: 100%|████████| 3552/3552 [21:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] loss=0.2178, time=1274.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.6649   2.7827: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.627, Accuracy=2.957\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.2243: 100%|████████| 3552/3552 [21:12<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] loss=0.2195, time=1272.8\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.6086   3.4342: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.627, Accuracy=3.016\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.2369: 100%|████████| 3552/3552 [21:08<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] loss=0.2170, time=1268.4\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.6993   3.2363: 100%|█| 1525/1525 [05:09<00:00,  4.92it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.632, Accuracy=2.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=patch_size, save_path='/app/HSK/FL_Seg/codes/ckpt_unet2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8c906b3"
   },
   "source": [
    "### 최고 성능 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running servers:\r\n",
      "http://0.0.0.0:8888/?token=ab00c708846767f39b9fa9233bace987e3786e8f554d1742 :: /\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter notebook list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1f298c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success\n"
     ]
    }
   ],
   "source": [
    "save_path=os.path.join(workspace_path, 'codes/ckpt_deepv3')\n",
    "\n",
    "checkpoint_path = os.path.join(save_path,'{}_best.pt'.format(model_name))\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "\n",
    "print('model load success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74453fb5"
   },
   "source": [
    "### 테스트 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "42e6ae95"
   },
   "outputs": [],
   "source": [
    "test_rgb_path = os.path.join(workspace_path, 'data/test/rgb')\n",
    "test_rgb_images = os.listdir(test_rgb_path)\n",
    "test_rgb_images = [os.path.join(test_rgb_path, x) for x in test_rgb_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dbeb921a"
   },
   "outputs": [],
   "source": [
    "#empty value\n",
    "test_label_path = os.path.join(workspace_path, 'data/test/label')\n",
    "try:\n",
    "    test_label_images = os.listdir(test_label_path)\n",
    "except:\n",
    "    test_label_images = []\n",
    "test_label_images = [os.path.join(test_label_path, x) for x in test_label_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1ba27f1e"
   },
   "outputs": [],
   "source": [
    "test_dataset = CloudDataset(test_rgb_images, test_label_images,\n",
    "                            transforms=val_transforms, is_train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a055ede"
   },
   "source": [
    "### 테스트 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eadca7d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 208/208 [00:48<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "result_path = os.path.join(workspace_path, 'results')\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "    for i, (imgs, img_path) in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        if model_name == 'deeplabv3':\n",
    "            preds = model(imgs)['out']\n",
    "        #elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "        #    preds = model(imgs)\n",
    "        #    h, w = preds.shape[2], preds.shape[3]\n",
    "        elif model_name == 'dilated_unet':\n",
    "            preds = model(imgs)\n",
    "        \n",
    "        pred_img = np.zeros((*list(preds.shape[2:]), 3), dtype=np.uint8)\n",
    "        _, idx = preds.squeeze(0).max(0)\n",
    "        pos = idx == 0\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 0]\n",
    "        pos = idx == 1\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 255]\n",
    "        pos = idx == 2\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 0]\n",
    "        pos = idx == 3\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 255]\n",
    "        \n",
    "        cv2.imwrite(os.path.join(result_path, os.path.basename(img_path[0])), pred_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18494383"
   },
   "source": [
    "### Run-Length Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1e8d274d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "f4ebad00"
   },
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "cd9e1cbb"
   },
   "outputs": [],
   "source": [
    "test_label_file_list = os.listdir(result_path)\n",
    "test_label_path_list = [os.path.join(result_path, x) for x in test_label_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "92c7170e"
   },
   "outputs": [],
   "source": [
    "rle_list = []\n",
    "for file_path in test_label_path_list:\n",
    "    img = cv2.imread(file_path)\n",
    "    rle = mask2rle(img)\n",
    "    rle_list.append(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9851d2ed"
   },
   "outputs": [],
   "source": [
    "my_dict = {'Image_Label':test_label_file_list, 'EncodedPixels':rle_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "b0873d66"
   },
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7c595d0d"
   },
   "outputs": [],
   "source": [
    "my_df.to_csv(os.path.join(workspace_path, 'submission_deepv3.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e74acfe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "baseline-clouds-segmentation-colab-ver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
