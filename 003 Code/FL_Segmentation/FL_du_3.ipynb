{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1NrfEiTnlLS"
   },
   "source": [
    "폴더 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = '/app/HSK/FL_Seg'  # 파일 업로드한 경로 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "summary = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86ea40c7"
   },
   "source": [
    "### 필요한 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lRfwuEL2--n-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations==0.4.6 in /home/user/.local/lib/python3.8/site-packages (0.4.6)\n",
      "Requirement already satisfied: scipy in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.5.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.19.5)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (5.4.1)\n",
      "Requirement already satisfied: Shapely in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.19.2)\n",
      "Requirement already satisfied: matplotlib in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.5.2)\n",
      "Requirement already satisfied: Pillow in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.1.0)\n",
      "Requirement already satisfied: imageio in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.19.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.14.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2022.5.4)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (21.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.33.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yacs in /home/user/.local/lib/python3.8/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from yacs) (5.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations==0.4.6\n",
    "!pip install   yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "52bbfdfb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "649609b1"
   },
   "source": [
    "### 재구현 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c35eec19"
   },
   "outputs": [],
   "source": [
    "def init_seeds(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    if seed == 0:  # slower, more reproducible\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = False\n",
    "    else:  # faster, less reproducible\n",
    "        cudnn.deterministic = False\n",
    "        cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "b90c4ec5"
   },
   "outputs": [],
   "source": [
    "init_seeds(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f8a343a"
   },
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "499b3f23"
   },
   "outputs": [],
   "source": [
    "rgb_path = os.path.join(workspace_path, 'data/train/rgb/')\n",
    "ngr_path = os.path.join(workspace_path, 'data/train/ngr/')\n",
    "label_path = os.path.join(workspace_path, 'data/train/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d4e26b49"
   },
   "outputs": [],
   "source": [
    "rgb_images = os.listdir(rgb_path) \n",
    "rgb_images = [os.path.join(rgb_path,x) for x in rgb_images]\n",
    "ngr_images = os.listdir(ngr_path)\n",
    "ngr_images = [os.path.join(ngr_path, x) for x in ngr_images]\n",
    "label_images = os.listdir(label_path)\n",
    "label_images = [os.path.join(label_path, x) for x in label_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997d5237"
   },
   "source": [
    "### 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ca96420c"
   },
   "outputs": [],
   "source": [
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, label_path, patch_size = 400, patch_stride = 100, is_train = True, cache_dir = './cache', transforms = None):\n",
    "        self.image_path = image_path\n",
    "        self.label_path = label_path\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_stride = patch_stride\n",
    "        self.is_train = is_train\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.patch_images = []\n",
    "        self.patch_labels = []\n",
    "        \n",
    "        \n",
    "        cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        if is_train:\n",
    "            for img_path in self.image_path:\n",
    "                img = cv2.imread(img_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'rgb_{os.path.splitext(os.path.basename(img_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_images.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "\n",
    "            for label_path in self.label_path:\n",
    "                img = cv2.imread(label_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'label_{os.path.splitext(os.path.basename(label_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_labels.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "        else:\n",
    "            self.patch_images = self.image_path\n",
    "            self.patch_labels = self.label_path\n",
    "    def __len__(self):\n",
    "        return len(self.patch_images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.patch_images[idx])\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = cv2.imread(self.patch_labels[idx])\n",
    "            # numpy arrays to tensors\n",
    "            h, w = label.shape[:2]\n",
    "        \n",
    "            target = np.zeros((h, w), dtype=np.uint8)\n",
    "            pos = np.where(np.all(label == [0, 0, 255], axis=-1))  # thick cloud\n",
    "            target[pos] = 1\n",
    "            pos = np.where(np.all(label == [0, 255, 0], axis=-1))  # thin cloud\n",
    "            target[pos] = 2\n",
    "            pos = np.where(np.all(label == [0, 255, 255], axis=-1))  # cloud shadow\n",
    "            target[pos] = 3\n",
    "        else:\n",
    "            target = None\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        if self.is_train:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, self.patch_images[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09d79e8b"
   },
   "source": [
    "### 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "a6ac4eae"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 20\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "patch_size = 400\n",
    "patch_stride = 100\n",
    "num_workers = 0\n",
    "\n",
    "num_classes = 4\n",
    "class_names = ['thick cloud', 'thin cloud', 'cloud shadow']\n",
    "\n",
    "train_data_rate = 0.7\n",
    "\n",
    "model_name = 'dilated_unet'\n",
    "\n",
    "loss_func = 'dice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e4513b1"
   },
   "source": [
    "### 데이터증대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "17dc2c12"
   },
   "outputs": [],
   "source": [
    "class ImageAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.HorizontalFlip(p=0.5),\n",
    "                             A.VerticalFlip(p=0.5),\n",
    "                             A.ShiftScaleRotate(p=0.5),\n",
    "                             A.RandomBrightnessContrast(p=0.3),\n",
    "                             A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']\n",
    "\n",
    "class DefaultAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "03a59423"
   },
   "outputs": [],
   "source": [
    "train_transforms = ImageAug()\n",
    "val_transforms = DefaultAug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2147f462"
   },
   "source": [
    "### 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "98bed485"
   },
   "outputs": [],
   "source": [
    "#train dataset\n",
    "clients = dict()\n",
    "for i in range(num_clients):\n",
    "    if i < (num_clients - 1):\n",
    "        train_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate*i/num_clients):int(len(rgb_images)*train_data_rate*(i+1)/num_clients)], \n",
    "                                     label_images[int(len(rgb_images)*train_data_rate*i/num_clients):int(len(label_images)*train_data_rate*(i+1)/num_clients)],\n",
    "                                    transforms=train_transforms, cache_dir=os.path.join(workspace_path, f'cache_{i}'))\n",
    "    else:\n",
    "        train_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate/num_clients*i):int(len(rgb_images)*train_data_rate)], \n",
    "                                     label_images[int(len(rgb_images)*train_data_rate/num_clients*i):int(len(rgb_images)*train_data_rate)],\n",
    "                                    transforms=train_transforms, cache_dir=os.path.join(workspace_path, f'cache_{i}'))\n",
    "        \n",
    "    clients[f'train_dataloader_{i}'] = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                                   num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "#valid dataset\n",
    "val_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate):], label_images[int(len(label_images)*train_data_rate):],\n",
    "                            transforms=val_transforms, cache_dir=os.path.join(workspace_path, 'cache_val'))\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in range(num_clients):\n",
    "    total += len(clients[f'train_dataloader_{i}'])\n",
    "\n",
    "len_clients = dict()\n",
    "for i in range(num_clients):   \n",
    "    len_clients[f'train_dataloader_{i}'] = len(clients[f'train_dataloader_{i}']) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataloader_0': 0.3327702702702703,\n",
       " 'train_dataloader_1': 0.3327702702702703,\n",
       " 'train_dataloader_2': 0.3344594594594595}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cbab53"
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "e54a2c7d"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eIK90NknzGPn"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DilatedConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation, padding):\n",
    "        super(DilatedConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, dilation=dilation),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConcatDoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConcatDoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((skip, x), dim=1)\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class MyDilatedConvUNet(nn.Module):\n",
    "    def __init__(self, filters=44, depth=3, bottleneck_depth=6):\n",
    "        super(MyDilatedConvUNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.encoder_path = nn.ModuleList()\n",
    "        src_in_channels = 3     # Geo-TIFF has four channels (R, G, B, and NIR)\n",
    "        for d in range(depth):\n",
    "            in_channels = src_in_channels if d == 0 else filters * 2 ** (d-1)\n",
    "            self.encoder_path.append(\n",
    "                DoubleConvBlock(in_channels, filters * 2 ** d))\n",
    "        self.maxpool = nn.MaxPool2d(2, 2, padding=0)\n",
    "        self.bottleneck_path = nn.ModuleList()\n",
    "        for d in range(bottleneck_depth):\n",
    "            in_channels = filters * 2 ** (depth - 1) if d == 0 else filters * 2 ** depth\n",
    "            self.bottleneck_path.append(DilatedConvBlock(in_channels, filters * 2 ** depth, 2 ** d, 2 ** d))\n",
    "        self.decoder_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.decoder_path.append(ConcatDoubleConvBlock(in_channels, filters * 2 ** (depth - d - 1)))\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.up_path.append(nn.ConvTranspose2d(in_channels, filters * 2 ** (depth - d - 1),\n",
    "                                                        kernel_size=4, stride=2, padding=1))\n",
    "        out_channels = 4     # output channels (num_classes + 1(background))\n",
    "        self.last_conv = nn.Conv2d(filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = []\n",
    "        for block in self.encoder_path:\n",
    "            x = block(x)\n",
    "            skip.append(x)\n",
    "            x = self.maxpool(x)\n",
    "        dilated = []\n",
    "        for block in self.bottleneck_path:\n",
    "            x = block(x)\n",
    "            dilated.append(x)\n",
    "        x = torch.stack(dilated, dim=-1).sum(dim=-1)  # sum over list\n",
    "\n",
    "        # up-sampling and double convolutions\n",
    "        for d in range(self.depth):\n",
    "            x = self.up_path[d](x)\n",
    "            x = self.decoder_path[d](x, skip[-(d+1)])\n",
    "\n",
    "        return self.last_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "78338b36"
   },
   "outputs": [],
   "source": [
    "# # Model\n",
    "# if model_name == 'deeplabv3':\n",
    "#     model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=4)\n",
    "\n",
    "# elif model_name == 'dilated_unet':\n",
    "#     model = MyDilatedConvUNet()\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# print('number of parameters: ', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "467743f7"
   },
   "source": [
    "### Opimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "314acf1e"
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuJfaks1zbtC"
   },
   "source": [
    "### 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "c124f5df"
   },
   "outputs": [],
   "source": [
    "def fitness_test(true, pred, num_classes=4):\n",
    "    eps = 1e-7\n",
    "    true_one_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_one_hot = true_one_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "    pred_max = pred.argmax(1)      # (B, C, H, W) to (B, H, W)\n",
    "    pix_acc = (true == pred_max.unsqueeze(1)).sum().float().div(true.nelement())\n",
    "    pred_one_hot = F.one_hot(pred_max, num_classes=num_classes)   # (B, H, W) to (B, H, W, C)\n",
    "    pred_one_hot = pred_one_hot.permute(0, 3, 1, 2)   # (B, H, W, C) to (B, C, H, W)\n",
    "\n",
    "    true_one_hot = true_one_hot.type(pred_one_hot.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))  # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(pred_one_hot & true_one_hot, dims)\n",
    "    union = torch.sum(pred_one_hot | true_one_hot, dims)\n",
    "    m_iou = (intersection / (union + eps)).mean()\n",
    "\n",
    "    return m_iou.item(), pix_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "v74FWycdzdev"
   },
   "outputs": [],
   "source": [
    "# Loss 함수 정의\n",
    "def ce_loss(true, logits, ignore=255):\n",
    "    \"\"\"Computes the weighted multi-class cross-entropy loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        ignore: the class index to ignore.\n",
    "    Returns:\n",
    "        ce_loss: the weighted multi-class cross-entropy loss.\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(\n",
    "        logits.float(),\n",
    "        true.squeeze(1).long(),    # [B, H, W]\n",
    "        ignore_index=ignore,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        # true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))        # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "def jaccard_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d1af165"
   },
   "source": [
    "### 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182\n",
      "1182\n",
      "1188\n"
     ]
    }
   ],
   "source": [
    "for train_dataloader in clients:\n",
    "    print(len(clients[train_dataloader]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clients[train_dataloader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt(f_name, weights):\n",
    "    with open(f\"./FL_du_v2_txt/{f_name}.txt\", \"w\") as f:\n",
    "        for p in weights:\n",
    "            f.write(p + \"\\n\")\n",
    "            f.write(str(weights[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = MyDilatedConvUNet().cuda()\n",
    "global_model.to(device)\n",
    "optimizer = torch.optim.Adam(global_model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "bad17d99"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, clients, val_dataloader, loss_func, epochs, device, patch_size=400, use_scheduler=False, save_path='./ckpt'):\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    if use_scheduler:\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "        \n",
    "    start_epoch = 0\n",
    "    resume = True\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    weight_file = save_path + '/{}.pt'.format(model_name)\n",
    "\n",
    "    best_fit = 0.0\n",
    "    num_epochs = epochs\n",
    "    \n",
    "    if resume:\n",
    "        if os.path.exists(weight_file):\n",
    "            checkpoint = torch.load(weight_file)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_fit = checkpoint['best_fit']\n",
    "            print(\"Starting training for %g epochs...\" % start_epoch)\n",
    "\n",
    "    # Start training\n",
    "    local_model = MyDilatedConvUNet().cuda()\n",
    "    temp_model = MyDilatedConvUNet().cuda()\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        # loss, metric = train_one_epoch(model, optimizer, dataloader, device, epoch)\n",
    "        t0 = time.time()\n",
    "        \n",
    "        clients_loss = []   \n",
    "        \n",
    "        save_txt(f'{epoch}_global_model_bf', model.state_dict()) ###### weights저장\n",
    "        \n",
    "        for train_dataloader in clients:\n",
    "            \n",
    "            local_model.load_state_dict(model.state_dict())\n",
    "            optimizer = torch.optim.Adam(local_model.parameters(), lr=3e-4)\n",
    "            \n",
    "            save_txt(f'{epoch}_{train_dataloader}_bf', local_model.state_dict()) ###### weights저장\n",
    "            \n",
    "            if train_dataloader == 'train_dataloader_0':\n",
    "                print(train_dataloader)\n",
    "                loss = train_one_epoch(local_model, optimizer, clients[train_dataloader], loss_func, device, epoch, num_epochs)\n",
    "                clients_loss.append(loss)\n",
    "                \n",
    "                temp_model.load_state_dict(local_model.state_dict())\n",
    "                \n",
    "                for p in temp_model.state_dict():\n",
    "                    if p[-7:] != 'tracked':\n",
    "                        temp_model.state_dict()[p] *= len_clients[train_dataloader]\n",
    "#                     temp_model.state_dict()[p] = copy.deepcopy(local_model.state_dict()[p]) * len_clients[train_dataloader]\n",
    "\n",
    "            else:\n",
    "                print(train_dataloader)\n",
    "                loss = train_one_epoch(local_model, optimizer, clients[train_dataloader], loss_func, device, epoch, num_epochs)\n",
    "                clients_loss.append(loss)\n",
    "#                 for p in local_model.state_dict():\n",
    "#                     if p[-7:] != 'tracked':\n",
    "#                         local_model.state_dict()[p] *= len_clients[train_dataloader]\n",
    "                        \n",
    "                for p in temp_model.state_dict():\n",
    "                    if p[-7:] != 'tracked':\n",
    "                        local_model.state_dict()[p] *= len_clients[train_dataloader]\n",
    "                        temp_model.state_dict()[p] += local_model.state_dict()[p]\n",
    "#                 for p in local_model.state_dict():\n",
    "#                     local_model.state_dict()[p] = local_model.state_dict()[p] * len_clients[train_dataloader] \n",
    "#                     temp_model.state_dict()[p] += local_model.state_dict()[p]\n",
    "            \n",
    "            save_txt(f'{epoch}_{train_dataloader}_l', local_model.state_dict()) ###### weights저장\n",
    "            save_txt(f'{epoch}_{train_dataloader}_t', temp_model.state_dict()) ###### weights저장\n",
    "            \n",
    "            \n",
    "            \n",
    "        t1 = time.time()\n",
    "        print('[Epoch %g] loss=%.4f, time=%.1f' % (epoch, sum(clients_loss) / len(clients_loss), t1 - t0))\n",
    "        \n",
    "        model.load_state_dict(temp_model.state_dict())\n",
    "        \n",
    "        save_txt(f'{epoch}_global_model_af', model.state_dict()) ###### weights저장\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "        \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step(loss)\n",
    "        #tb_writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        state = {'model_name': model_name, 'epoch': epoch, 'best_fit': best_fit, 'model': model.state_dict()}\n",
    "        torch.save(state, weight_file)\n",
    "\n",
    "        #tb_writer.add_scalar('train_epoch_loss', loss, epoch)\n",
    "        \n",
    "        torch.save(state, save_path + '/{}.pt'.format(model_name)) \n",
    "        \n",
    "        # validation\n",
    "        patch_size = patch_size\n",
    "        fit = val_one_epoch(model, val_dataloader, device, epoch, num_epochs, patch_size)\n",
    "        if fit > best_fit:\n",
    "            print(\"best fit so far=>saved\")\n",
    "            torch.save(state, save_path + '/{}_best.pt'.format(model_name))\n",
    "            best_fit = fit\n",
    "        torch.save(state, save_path + '/{}.pt'.format(model_name))    \n",
    "    #         writer.add_scalar('D_loss_adv', d_loss_adv.item(), epoch)\n",
    "    #         writer.add_scalar('D_loss_cls', d_loss_cls.item(), epoch)\n",
    "\n",
    "\n",
    "def train_one_epoch(local_model, optimizer, data_loader, loss_func, device, epoch, num_epochs):    \n",
    "#     if torch.cuda.is_available():\n",
    "#             local_model.cuda()\n",
    "    local_model.to(device)\n",
    "    local_model.train()\n",
    "    \n",
    "    \n",
    "    \n",
    "    losses = np.array([])\n",
    "    metrics = np.array([])\n",
    "    bi0 = epoch * len(data_loader)  # batch index\n",
    "\n",
    "    print(('\\n' + '%10s' * 2) % ('Epoch', 'loss'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0)\n",
    "    pbar.set_description(s)\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "        if model_name == 'dilated_unet':\n",
    "            preds = local_model(imgs)\n",
    "            targets = targets.long()\n",
    "            \n",
    "        if loss_func == 'jaccard':\n",
    "            loss = jaccard_loss(targets, preds)\n",
    "        elif loss_func == 'dice':\n",
    "            loss = dice_loss(targets, preds)\n",
    "        elif loss_func == 'ce':\n",
    "            loss = ce_loss(targets, preds)\n",
    "        else:\n",
    "            print('unsupported loss function')\n",
    "            exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # cv2_imshow(imgs[0], preds[0])\n",
    "            losses = np.append(losses, loss.item())\n",
    "\n",
    "            s = ('%10s' + '%10.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), loss.item())\n",
    "            pbar.set_description(s)\n",
    "            bi = bi0 + i\n",
    "            #tb_writer.add_scalar('train_batch_loss', loss.item(), bi)\n",
    "\n",
    "    epoch_loss = losses.mean()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def val_one_epoch(local_model, data_loader, device, epoch, num_epochs, patch_size):\n",
    "    local_model.eval()\n",
    "    m_iou_list = np.array([])\n",
    "    pix_acc_list = np.array([])\n",
    "\n",
    "    print(('\\n' + '%10s' * 3) % ('Epoch(V)', 'mIOU', 'Accuracy'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0, 0.0)\n",
    "    pbar.set_description(s)\n",
    "\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            if model_name == 'dilated_unet':\n",
    "                preds = local_model(imgs)\n",
    "                targets = targets.long()\n",
    "\n",
    "            m_iou, pix_acc = fitness_test(targets, preds)\n",
    "\n",
    "            s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), m_iou, pix_acc)\n",
    "            pbar.set_description(s)\n",
    "            m_iou_list = np.append(m_iou_list, m_iou)\n",
    "            pix_acc_list = np.append(pix_acc_list, pix_acc)\n",
    "    val_m_iou_mean = m_iou_list.mean()\n",
    "    val_pix_acc_mean = pix_acc_list.mean()\n",
    "    print('[V] mIOU={:.3f}, Accuracy={:.3f}'.format(val_m_iou_mean, val_pix_acc_mean))\n",
    "    #tb_writer.add_scalar('val_epoch_m_iou', val_m_iou_mean, epoch)\n",
    "    #tb_writer.add_scalar('val_epoch_pix_acc', val_pix_acc_mean, epoch)\n",
    "    return val_pix_acc_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "600d9790"
   },
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "b74e3dff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.4584: 100%|████████| 1182/1182 [09:02<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.3682: 100%|████████| 1182/1182 [09:05<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.4225: 100%|████████| 1188/1188 [09:05<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] loss=0.3643, time=1640.5\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.5416   3.9097: 100%|█| 1525/1525 [05:12<00:00,  4.88it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.529, Accuracy=3.045\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.5043: 100%|████████| 1182/1182 [09:13<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.3133: 100%|████████| 1182/1182 [09:06<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.4447: 100%|████████| 1188/1188 [09:06<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.3626, time=1653.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.4408   2.8613: 100%|█| 1525/1525 [05:14<00:00,  4.86it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.504, Accuracy=3.103\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.2456: 100%|████████| 1182/1182 [09:04<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.5854: 100%|████████| 1182/1182 [09:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.3887: 100%|████████| 1188/1188 [09:09<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.3553, time=1641.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.4462   2.8551: 100%|█| 1525/1525 [05:18<00:00,  4.79it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.549, Accuracy=2.957\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.3840: 100%|████████| 1182/1182 [09:03<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.3191: 100%|████████| 1182/1182 [09:06<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.4421: 100%|████████| 1188/1188 [09:11<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.3491, time=1647.5\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.5248   2.7687: 100%|█| 1525/1525 [05:21<00:00,  4.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.506, Accuracy=3.031\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.4011: 100%|████████| 1182/1182 [09:04<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.3571: 100%|████████| 1182/1182 [09:08<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.3946: 100%|████████| 1188/1188 [09:14<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] loss=0.3444, time=1653.8\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.6807   3.0241: 100%|█| 1525/1525 [05:24<00:00,  4.70it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.565, Accuracy=3.061\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.3704: 100%|████████| 1182/1182 [09:02<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.3949: 100%|████████| 1182/1182 [09:05<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.2587: 100%|████████| 1188/1188 [09:06<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] loss=0.3384, time=1642.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.5617   2.9733: 100%|█| 1525/1525 [05:28<00:00,  4.64it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.518, Accuracy=3.118\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.4291: 100%|████████| 1182/1182 [09:03<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.2502: 100%|████████| 1182/1182 [09:07<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.3065: 100%|████████| 1188/1188 [09:09<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] loss=0.3362, time=1647.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.5019   2.4050: 100%|█| 1525/1525 [05:31<00:00,  4.61it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.507, Accuracy=2.899\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.3337: 100%|████████| 1182/1182 [09:02<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.5074: 100%|████████| 1182/1182 [09:05<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.3566: 100%|████████| 1188/1188 [09:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] loss=0.3282, time=1652.7\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.4086   3.0606: 100%|█| 1525/1525 [05:35<00:00,  4.55it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.514, Accuracy=3.082\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.2743: 100%|████████| 1182/1182 [08:59<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.3627: 100%|████████| 1182/1182 [09:10<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.4208: 100%|████████| 1188/1188 [09:07<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] loss=0.3259, time=1644.4\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.4552   2.6044: 100%|█| 1525/1525 [05:38<00:00,  4.50it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.518, Accuracy=3.100\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.3365: 100%|████████| 1182/1182 [08:58<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.2859: 100%|████████| 1182/1182 [09:05<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.1489: 100%|████████| 1188/1188 [09:09<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] loss=0.3205, time=1640.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.4992   4.3206: 100%|█| 1525/1525 [05:41<00:00,  4.46it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.507, Accuracy=2.981\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.2688: 100%|████████| 1182/1182 [08:59<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.2918: 100%|████████| 1182/1182 [09:06<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.1483: 100%|████████| 1188/1188 [09:11<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss=0.3131, time=1644.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.4636   2.7410: 100%|█| 1525/1525 [05:44<00:00,  4.42it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.494, Accuracy=3.136\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.2082: 100%|████████| 1182/1182 [09:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.4546: 100%|████████| 1182/1182 [09:07<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.3565: 100%|████████| 1188/1188 [09:11<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] loss=0.3105, time=1647.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.4381   3.2142: 100%|█| 1525/1525 [05:48<00:00,  4.38it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.550, Accuracy=3.108\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.4827: 100%|████████| 1182/1182 [08:59<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.2432: 100%|████████| 1182/1182 [09:05<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.3899: 100%|████████| 1188/1188 [09:08<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] loss=0.3076, time=1639.7\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.5522   2.3537: 100%|█| 1525/1525 [05:52<00:00,  4.33it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.521, Accuracy=3.022\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.4000: 100%|████████| 1182/1182 [08:58<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.4662: 100%|████████| 1182/1182 [09:06<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.3494: 100%|████████| 1188/1188 [09:07<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] loss=0.3044, time=1639.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.5912   3.0573: 100%|█| 1525/1525 [05:54<00:00,  4.30it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.540, Accuracy=3.085\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.2659: 100%|████████| 1182/1182 [08:57<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.3107: 100%|████████| 1182/1182 [09:09<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.2098: 100%|████████| 1188/1188 [09:10<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] loss=0.2977, time=1644.6\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.6611   2.8783: 100%|█| 1525/1525 [05:57<00:00,  4.26it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.560, Accuracy=3.073\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.2433: 100%|████████| 1182/1182 [08:59<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.3068: 100%|████████| 1182/1182 [09:09<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.2427: 100%|████████| 1188/1188 [09:11<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] loss=0.2983, time=1646.4\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.4904   2.5916: 100%|█| 1525/1525 [06:02<00:00,  4.21it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.557, Accuracy=3.084\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.2960: 100%|████████| 1182/1182 [09:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.3724: 100%|████████| 1182/1182 [09:03<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.3440: 100%|████████| 1188/1188 [09:07<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] loss=0.2959, time=1637.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.3274   2.7753: 100%|█| 1525/1525 [06:05<00:00,  4.17it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.519, Accuracy=3.165\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.2276: 100%|████████| 1182/1182 [08:57<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.2800: 100%|████████| 1182/1182 [09:06<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.2814: 100%|████████| 1188/1188 [09:09<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] loss=0.2917, time=1640.8\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.4627   2.2841: 100%|█| 1525/1525 [06:08<00:00,  4.14it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.577, Accuracy=3.036\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.4443: 100%|████████| 1182/1182 [09:02<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.2442: 100%|████████| 1182/1182 [09:03<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.2619: 100%|████████| 1188/1188 [09:11<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] loss=0.2857, time=1644.5\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.5796   3.0432: 100%|█| 1525/1525 [06:11<00:00,  4.10it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.533, Accuracy=3.103\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.2465: 100%|████████| 1182/1182 [08:55<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.3434: 100%|████████| 1182/1182 [09:08<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.2587: 100%|████████| 1188/1188 [09:10<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] loss=0.2851, time=1641.3\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.6596   4.4064: 100%|█| 1525/1525 [06:15<00:00,  4.06it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.555, Accuracy=3.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(global_model, optimizer, clients, val_dataloader, loss_func, epochs, device, patch_size=patch_size, save_path='/app/HSK/FL_Seg/codes/ckpt_FL_du_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8c906b3"
   },
   "source": [
    "### 최고 성능 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1f298c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success\n"
     ]
    }
   ],
   "source": [
    "save_path=os.path.join(workspace_path, 'codes/ckpt_deepv3')\n",
    "\n",
    "checkpoint_path = os.path.join(save_path,'{}_best.pt'.format(model_name))\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "\n",
    "print('model load success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74453fb5"
   },
   "source": [
    "### 테스트 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "42e6ae95"
   },
   "outputs": [],
   "source": [
    "test_rgb_path = os.path.join(workspace_path, 'data/test/rgb')\n",
    "test_rgb_images = os.listdir(test_rgb_path)\n",
    "test_rgb_images = [os.path.join(test_rgb_path, x) for x in test_rgb_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dbeb921a"
   },
   "outputs": [],
   "source": [
    "#empty value\n",
    "test_label_path = os.path.join(workspace_path, 'data/test/label')\n",
    "try:\n",
    "    test_label_images = os.listdir(test_label_path)\n",
    "except:\n",
    "    test_label_images = []\n",
    "test_label_images = [os.path.join(test_label_path, x) for x in test_label_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1ba27f1e"
   },
   "outputs": [],
   "source": [
    "test_dataset = CloudDataset(test_rgb_images, test_label_images,\n",
    "                            transforms=val_transforms, is_train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a055ede"
   },
   "source": [
    "### 테스트 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eadca7d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 208/208 [00:48<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "result_path = os.path.join(workspace_path, 'results')\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "    for i, (imgs, img_path) in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        if model_name == 'deeplabv3':\n",
    "            preds = model(imgs)['out']\n",
    "        #elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n",
    "        #    preds = model(imgs)\n",
    "        #    h, w = preds.shape[2], preds.shape[3]\n",
    "        elif model_name == 'dilated_unet':\n",
    "            preds = model(imgs)\n",
    "        \n",
    "        pred_img = np.zeros((*list(preds.shape[2:]), 3), dtype=np.uint8)\n",
    "        _, idx = preds.squeeze(0).max(0)\n",
    "        pos = idx == 0\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 0]\n",
    "        pos = idx == 1\n",
    "        pred_img[pos.cpu().numpy()] = [0, 0, 255]\n",
    "        pos = idx == 2\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 0]\n",
    "        pos = idx == 3\n",
    "        pred_img[pos.cpu().numpy()] = [0, 255, 255]\n",
    "        \n",
    "        cv2.imwrite(os.path.join(result_path, os.path.basename(img_path[0])), pred_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18494383"
   },
   "source": [
    "### Run-Length Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1e8d274d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "f4ebad00"
   },
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "cd9e1cbb"
   },
   "outputs": [],
   "source": [
    "test_label_file_list = os.listdir(result_path)\n",
    "test_label_path_list = [os.path.join(result_path, x) for x in test_label_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "92c7170e"
   },
   "outputs": [],
   "source": [
    "rle_list = []\n",
    "for file_path in test_label_path_list:\n",
    "    img = cv2.imread(file_path)\n",
    "    rle = mask2rle(img)\n",
    "    rle_list.append(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9851d2ed"
   },
   "outputs": [],
   "source": [
    "my_dict = {'Image_Label':test_label_file_list, 'EncodedPixels':rle_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "b0873d66"
   },
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7c595d0d"
   },
   "outputs": [],
   "source": [
    "my_df.to_csv(os.path.join(workspace_path, 'submission_deepv3.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "baseline-clouds-segmentation-colab-ver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
