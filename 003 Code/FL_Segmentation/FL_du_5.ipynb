{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1NrfEiTnlLS"
   },
   "source": [
    "폴더 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = '/app/HSK/FL_Seg'  # 파일 업로드한 경로 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "summary = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86ea40c7"
   },
   "source": [
    "### 필요한 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lRfwuEL2--n-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations==0.4.6 in /home/user/.local/lib/python3.8/site-packages (0.4.6)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (0.4.0)\n",
      "Requirement already satisfied: scipy in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (1.19.5)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (5.4.1)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /home/user/.local/lib/python3.8/site-packages (from albumentations==0.4.6) (4.5.5.64)\n",
      "Requirement already satisfied: Pillow in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.1.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.19.2)\n",
      "Requirement already satisfied: Shapely in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n",
      "Requirement already satisfied: imageio in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.19.1)\n",
      "Requirement already satisfied: matplotlib in /home/user/.local/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.5.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2022.5.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/.local/lib/python3.8/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yacs in /home/user/.local/lib/python3.8/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /home/user/.local/lib/python3.8/site-packages (from yacs) (5.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations==0.4.6\n",
    "!pip install   yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "52bbfdfb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "649609b1"
   },
   "source": [
    "### 재구현 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c35eec19"
   },
   "outputs": [],
   "source": [
    "def init_seeds(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    if seed == 0:  # slower, more reproducible\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = False\n",
    "    else:  # faster, less reproducible\n",
    "        cudnn.deterministic = False\n",
    "        cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b90c4ec5"
   },
   "outputs": [],
   "source": [
    "init_seeds(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f8a343a"
   },
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "499b3f23"
   },
   "outputs": [],
   "source": [
    "rgb_path = os.path.join(workspace_path, 'data/train/rgb/')\n",
    "ngr_path = os.path.join(workspace_path, 'data/train/ngr/')\n",
    "label_path = os.path.join(workspace_path, 'data/train/label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d4e26b49"
   },
   "outputs": [],
   "source": [
    "rgb_images = os.listdir(rgb_path)\n",
    "rgb_images = [os.path.join(rgb_path,x) for x in rgb_images]\n",
    "ngr_images = os.listdir(ngr_path)\n",
    "ngr_images = [os.path.join(ngr_path, x) for x in ngr_images]\n",
    "label_images = os.listdir(label_path)\n",
    "label_images = [os.path.join(label_path, x) for x in label_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997d5237"
   },
   "source": [
    "### 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ca96420c"
   },
   "outputs": [],
   "source": [
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, label_path, patch_size = 400, patch_stride = 100, is_train = True, cache_dir = './cache', transforms = None):\n",
    "        self.image_path = image_path\n",
    "        self.label_path = label_path\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_stride = patch_stride\n",
    "        self.is_train = is_train\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.patch_images = []\n",
    "        self.patch_labels = []\n",
    "        \n",
    "        \n",
    "        cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        if is_train:\n",
    "            for img_path in self.image_path:\n",
    "                img = cv2.imread(img_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'rgb_{os.path.splitext(os.path.basename(img_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_images.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "\n",
    "            for label_path in self.label_path:\n",
    "                img = cv2.imread(label_path)\n",
    "                img_count = 0\n",
    "                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n",
    "                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n",
    "                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n",
    "                        patch_path = f'label_{os.path.splitext(os.path.basename(label_path))[0]}_{img_count}.png'\n",
    "                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n",
    "                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n",
    "                        self.patch_labels.append(os.path.join(cache_dir, patch_path))\n",
    "                        img_count += 1\n",
    "        else:\n",
    "            self.patch_images = self.image_path\n",
    "            self.patch_labels = self.label_path\n",
    "    def __len__(self):\n",
    "        return len(self.patch_images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.patch_images[idx])\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = cv2.imread(self.patch_labels[idx])\n",
    "            # numpy arrays to tensors\n",
    "            h, w = label.shape[:2]\n",
    "        \n",
    "            target = np.zeros((h, w), dtype=np.uint8)\n",
    "            pos = np.where(np.all(label == [0, 0, 255], axis=-1))  # thick cloud\n",
    "            target[pos] = 1\n",
    "            pos = np.where(np.all(label == [0, 255, 0], axis=-1))  # thin cloud\n",
    "            target[pos] = 2\n",
    "            pos = np.where(np.all(label == [0, 255, 255], axis=-1))  # cloud shadow\n",
    "            target[pos] = 3\n",
    "        else:\n",
    "            target = None\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        if self.is_train:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, self.patch_images[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09d79e8b"
   },
   "source": [
    "### 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a6ac4eae"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 20\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "patch_size = 400\n",
    "patch_stride = 100\n",
    "num_workers = 0\n",
    "\n",
    "num_classes = 4\n",
    "class_names = ['thick cloud', 'thin cloud', 'cloud shadow']\n",
    "\n",
    "train_data_rate = 0.7\n",
    "\n",
    "model_name = 'dilated_unet'\n",
    "\n",
    "loss_func = 'dice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e4513b1"
   },
   "source": [
    "### 데이터증대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "17dc2c12"
   },
   "outputs": [],
   "source": [
    "class ImageAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.HorizontalFlip(p=0.5),\n",
    "                             A.VerticalFlip(p=0.5),\n",
    "                             A.ShiftScaleRotate(p=0.5),\n",
    "                             A.RandomBrightnessContrast(p=0.3),\n",
    "                             A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']\n",
    "\n",
    "class DefaultAug:\n",
    "    def __init__(self):\n",
    "        self.aug = A.Compose([A.Normalize(),\n",
    "                             ToTensorV2()])\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=label)\n",
    "        return transformed['image'], transformed['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "03a59423"
   },
   "outputs": [],
   "source": [
    "train_transforms = ImageAug()\n",
    "val_transforms = DefaultAug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2147f462"
   },
   "source": [
    "### 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "98bed485"
   },
   "outputs": [],
   "source": [
    "#train dataset\n",
    "clients = dict()\n",
    "for i in range(num_clients):\n",
    "    if i < (num_clients - 1):\n",
    "        train_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate*i/num_clients):int(len(rgb_images)*train_data_rate*(i+1)/num_clients)], \n",
    "                                     label_images[int(len(rgb_images)*train_data_rate*i/num_clients):int(len(label_images)*train_data_rate*(i+1)/num_clients)],\n",
    "                                    transforms=train_transforms, cache_dir=os.path.join(workspace_path, f'cache_{i}'))\n",
    "    else:\n",
    "        train_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate/num_clients*i):int(len(rgb_images)*train_data_rate)], \n",
    "                                     label_images[int(len(rgb_images)*train_data_rate/num_clients*i):int(len(rgb_images)*train_data_rate)],\n",
    "                                    transforms=train_transforms, cache_dir=os.path.join(workspace_path, f'cache_{i}'))\n",
    "        \n",
    "    clients[f'train_dataloader_{i}'] = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                                   num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "#valid dataset\n",
    "val_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate):], label_images[int(len(label_images)*train_data_rate):],\n",
    "                            transforms=val_transforms, cache_dir=os.path.join(workspace_path, 'cache_val'))\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in range(num_clients):\n",
    "    total += len(clients[f'train_dataloader_{i}'])\n",
    "\n",
    "len_clients = dict()\n",
    "for i in range(num_clients):   \n",
    "    len_clients[f'train_dataloader_{i}'] = len(clients[f'train_dataloader_{i}']) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataloader_0': 0.2,\n",
       " 'train_dataloader_1': 0.2,\n",
       " 'train_dataloader_2': 0.2,\n",
       " 'train_dataloader_3': 0.2,\n",
       " 'train_dataloader_4': 0.2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cbab53"
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "e54a2c7d"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eIK90NknzGPn"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DilatedConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation, padding):\n",
    "        super(DilatedConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, dilation=dilation),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConcatDoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConcatDoubleConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((skip, x), dim=1)\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class MyDilatedConvUNet(nn.Module):\n",
    "    def __init__(self, filters=44, depth=3, bottleneck_depth=6):\n",
    "        super(MyDilatedConvUNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.encoder_path = nn.ModuleList()\n",
    "        src_in_channels = 3     # Geo-TIFF has four channels (R, G, B, and NIR)\n",
    "        for d in range(depth):\n",
    "            in_channels = src_in_channels if d == 0 else filters * 2 ** (d-1)\n",
    "            self.encoder_path.append(\n",
    "                DoubleConvBlock(in_channels, filters * 2 ** d))\n",
    "        self.maxpool = nn.MaxPool2d(2, 2, padding=0)\n",
    "        self.bottleneck_path = nn.ModuleList()\n",
    "        for d in range(bottleneck_depth):\n",
    "            in_channels = filters * 2 ** (depth - 1) if d == 0 else filters * 2 ** depth\n",
    "            self.bottleneck_path.append(DilatedConvBlock(in_channels, filters * 2 ** depth, 2 ** d, 2 ** d))\n",
    "        self.decoder_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.decoder_path.append(ConcatDoubleConvBlock(in_channels, filters * 2 ** (depth - d - 1)))\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            in_channels = filters * 2 ** (depth - d)\n",
    "            self.up_path.append(nn.ConvTranspose2d(in_channels, filters * 2 ** (depth - d - 1),\n",
    "                                                        kernel_size=4, stride=2, padding=1))\n",
    "        out_channels = 4     # output channels (num_classes + 1(background))\n",
    "        self.last_conv = nn.Conv2d(filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = []\n",
    "        for block in self.encoder_path:\n",
    "            x = block(x)\n",
    "            skip.append(x)\n",
    "            x = self.maxpool(x)\n",
    "        dilated = []\n",
    "        for block in self.bottleneck_path:\n",
    "            x = block(x)\n",
    "            dilated.append(x)\n",
    "        x = torch.stack(dilated, dim=-1).sum(dim=-1)  # sum over list\n",
    "\n",
    "        # up-sampling and double convolutions\n",
    "        for d in range(self.depth):\n",
    "            x = self.up_path[d](x)\n",
    "            x = self.decoder_path[d](x, skip[-(d+1)])\n",
    "\n",
    "        return self.last_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "78338b36"
   },
   "outputs": [],
   "source": [
    "# # Model\n",
    "# if model_name == 'deeplabv3':\n",
    "#     model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=4)\n",
    "\n",
    "# elif model_name == 'dilated_unet':\n",
    "#     model = MyDilatedConvUNet()\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# print('number of parameters: ', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "467743f7"
   },
   "source": [
    "### Opimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "314acf1e"
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuJfaks1zbtC"
   },
   "source": [
    "### 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "c124f5df"
   },
   "outputs": [],
   "source": [
    "def fitness_test(true, pred, num_classes=4):\n",
    "    eps = 1e-7\n",
    "    true_one_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_one_hot = true_one_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "    pred_max = pred.argmax(1)      # (B, C, H, W) to (B, H, W)\n",
    "    pix_acc = (true == pred_max.unsqueeze(1)).sum().float().div(true.nelement())\n",
    "    pred_one_hot = F.one_hot(pred_max, num_classes=num_classes)   # (B, H, W) to (B, H, W, C)\n",
    "    pred_one_hot = pred_one_hot.permute(0, 3, 1, 2)   # (B, H, W, C) to (B, C, H, W)\n",
    "\n",
    "    true_one_hot = true_one_hot.type(pred_one_hot.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))  # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(pred_one_hot & true_one_hot, dims)\n",
    "    union = torch.sum(pred_one_hot | true_one_hot, dims)\n",
    "    m_iou = (intersection / (union + eps)).mean()\n",
    "\n",
    "    return m_iou.item(), pix_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "v74FWycdzdev"
   },
   "outputs": [],
   "source": [
    "# Loss 함수 정의\n",
    "def ce_loss(true, logits, ignore=255):\n",
    "    \"\"\"Computes the weighted multi-class cross-entropy loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        ignore: the class index to ignore.\n",
    "    Returns:\n",
    "        ce_loss: the weighted multi-class cross-entropy loss.\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(\n",
    "        logits.float(),\n",
    "        true.squeeze(1).long(),    # [B, H, W]\n",
    "        ignore_index=ignore,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        # true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))        # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "def jaccard_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d1af165"
   },
   "source": [
    "### 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n",
      "710\n",
      "710\n",
      "710\n",
      "710\n"
     ]
    }
   ],
   "source": [
    "for train_dataloader in clients:\n",
    "    print(len(clients[train_dataloader]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clients[train_dataloader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt(f_name, weights):\n",
    "    with open(f\"./FL_du_v2_txt/{f_name}.txt\", \"w\") as f:\n",
    "        for p in weights:\n",
    "            f.write(p + \"\\n\")\n",
    "            f.write(str(weights[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = MyDilatedConvUNet().cuda()\n",
    "global_model.to(device)\n",
    "optimizer = torch.optim.Adam(global_model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "bad17d99"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, clients, val_dataloader, loss_func, epochs, device, patch_size=400, use_scheduler=False, save_path='./ckpt'):\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    if use_scheduler:\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "        \n",
    "    start_epoch = 0\n",
    "    resume = True\n",
    "\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    weight_file = save_path + '/{}.pt'.format(model_name)\n",
    "\n",
    "    best_fit = 0.0\n",
    "    num_epochs = epochs\n",
    "    \n",
    "    if resume:\n",
    "        if os.path.exists(weight_file):\n",
    "            checkpoint = torch.load(weight_file)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_fit = checkpoint['best_fit']\n",
    "            print(\"Starting training for %g epochs...\" % start_epoch)\n",
    "\n",
    "    # Start training\n",
    "    local_model = MyDilatedConvUNet().cuda()\n",
    "    temp_model = MyDilatedConvUNet().cuda()\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        # loss, metric = train_one_epoch(model, optimizer, dataloader, device, epoch)\n",
    "        t0 = time.time()\n",
    "        \n",
    "        clients_loss = []   \n",
    "        \n",
    "        save_txt(f'{epoch}_global_model_bf', model.state_dict()) ###### weights저장\n",
    "        \n",
    "        for train_dataloader in clients:\n",
    "            \n",
    "            local_model.load_state_dict(model.state_dict())\n",
    "            optimizer = torch.optim.Adam(local_model.parameters(), lr=3e-4)\n",
    "            \n",
    "            save_txt(f'{epoch}_{train_dataloader}_bf', local_model.state_dict()) ###### weights저장\n",
    "            \n",
    "            if train_dataloader == 'train_dataloader_0':\n",
    "                print(train_dataloader)\n",
    "                loss = train_one_epoch(local_model, optimizer, clients[train_dataloader], loss_func, device, epoch, num_epochs)\n",
    "                clients_loss.append(loss)\n",
    "                \n",
    "                temp_model.load_state_dict(local_model.state_dict())\n",
    "                \n",
    "                for p in temp_model.state_dict():\n",
    "                    if p[-7:] != 'tracked':\n",
    "                        temp_model.state_dict()[p] *= len_clients[train_dataloader]\n",
    "#                     temp_model.state_dict()[p] = copy.deepcopy(local_model.state_dict()[p]) * len_clients[train_dataloader]\n",
    "\n",
    "            else:\n",
    "                print(train_dataloader)\n",
    "                loss = train_one_epoch(local_model, optimizer, clients[train_dataloader], loss_func, device, epoch, num_epochs)\n",
    "                clients_loss.append(loss)\n",
    "#                 for p in local_model.state_dict():\n",
    "#                     if p[-7:] != 'tracked':\n",
    "#                         local_model.state_dict()[p] *= len_clients[train_dataloader]\n",
    "                        \n",
    "                for p in temp_model.state_dict():\n",
    "                    if p[-7:] != 'tracked':\n",
    "                        local_model.state_dict()[p] *= len_clients[train_dataloader]\n",
    "                        temp_model.state_dict()[p] += local_model.state_dict()[p]\n",
    "#                 for p in local_model.state_dict():\n",
    "#                     local_model.state_dict()[p] = local_model.state_dict()[p] * len_clients[train_dataloader] \n",
    "#                     temp_model.state_dict()[p] += local_model.state_dict()[p]\n",
    "            \n",
    "            save_txt(f'{epoch}_{train_dataloader}_l', local_model.state_dict()) ###### weights저장\n",
    "            save_txt(f'{epoch}_{train_dataloader}_t', temp_model.state_dict()) ###### weights저장\n",
    "            \n",
    "            \n",
    "            \n",
    "        t1 = time.time()\n",
    "        print('[Epoch %g] loss=%.4f, time=%.1f' % (epoch, sum(clients_loss) / len(clients_loss), t1 - t0))\n",
    "        \n",
    "        model.load_state_dict(temp_model.state_dict())\n",
    "        \n",
    "        save_txt(f'{epoch}_global_model_af', model.state_dict()) ###### weights저장\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "        \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step(loss)\n",
    "        #tb_writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        state = {'model_name': model_name, 'epoch': epoch, 'best_fit': best_fit, 'model': model.state_dict()}\n",
    "        torch.save(state, weight_file)\n",
    "\n",
    "        #tb_writer.add_scalar('train_epoch_loss', loss, epoch)\n",
    "        \n",
    "        torch.save(state, save_path + '/{}.pt'.format(model_name)) \n",
    "        \n",
    "        # validation\n",
    "        patch_size = patch_size\n",
    "        fit = val_one_epoch(model, val_dataloader, device, epoch, num_epochs, patch_size)\n",
    "        if fit > best_fit:\n",
    "            print(\"best fit so far=>saved\")\n",
    "            torch.save(state, save_path + '/{}_best.pt'.format(model_name))\n",
    "            best_fit = fit\n",
    "        torch.save(state, save_path + '/{}.pt'.format(model_name))    \n",
    "    #         writer.add_scalar('D_loss_adv', d_loss_adv.item(), epoch)\n",
    "    #         writer.add_scalar('D_loss_cls', d_loss_cls.item(), epoch)\n",
    "\n",
    "\n",
    "def train_one_epoch(local_model, optimizer, data_loader, loss_func, device, epoch, num_epochs):    \n",
    "#     if torch.cuda.is_available():\n",
    "#             local_model.cuda()\n",
    "    local_model.to(device)\n",
    "    local_model.train()\n",
    "    \n",
    "    \n",
    "    \n",
    "    losses = np.array([])\n",
    "    metrics = np.array([])\n",
    "    bi0 = epoch * len(data_loader)  # batch index\n",
    "\n",
    "    print(('\\n' + '%10s' * 2) % ('Epoch', 'loss'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0)\n",
    "    pbar.set_description(s)\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "        if model_name == 'dilated_unet':\n",
    "            preds = local_model(imgs)\n",
    "            targets = targets.long()\n",
    "            \n",
    "        if loss_func == 'jaccard':\n",
    "            loss = jaccard_loss(targets, preds)\n",
    "        elif loss_func == 'dice':\n",
    "            loss = dice_loss(targets, preds)\n",
    "        elif loss_func == 'ce':\n",
    "            loss = ce_loss(targets, preds)\n",
    "        else:\n",
    "            print('unsupported loss function')\n",
    "            exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # cv2_imshow(imgs[0], preds[0])\n",
    "            losses = np.append(losses, loss.item())\n",
    "\n",
    "            s = ('%10s' + '%10.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), loss.item())\n",
    "            pbar.set_description(s)\n",
    "            bi = bi0 + i\n",
    "            #tb_writer.add_scalar('train_batch_loss', loss.item(), bi)\n",
    "\n",
    "    epoch_loss = losses.mean()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def val_one_epoch(local_model, data_loader, device, epoch, num_epochs, patch_size):\n",
    "    local_model.eval()\n",
    "    m_iou_list = np.array([])\n",
    "    pix_acc_list = np.array([])\n",
    "\n",
    "    print(('\\n' + '%10s' * 3) % ('Epoch(V)', 'mIOU', 'Accuracy'))\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "        '-/%g' % (num_epochs - 1), 0.0, 0.0)\n",
    "    pbar.set_description(s)\n",
    "\n",
    "    for i, (imgs, targets) in pbar:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            if model_name == 'dilated_unet':\n",
    "                preds = local_model(imgs)\n",
    "                targets = targets.long()\n",
    "\n",
    "            m_iou, pix_acc = fitness_test(targets, preds)\n",
    "\n",
    "            s = ('%10s' + '%10.4f' + ' %8.4f') % (\n",
    "                '%g/%g' % (epoch, num_epochs - 1), m_iou, pix_acc)\n",
    "            pbar.set_description(s)\n",
    "            m_iou_list = np.append(m_iou_list, m_iou)\n",
    "            pix_acc_list = np.append(pix_acc_list, pix_acc)\n",
    "    val_m_iou_mean = m_iou_list.mean()\n",
    "    val_pix_acc_mean = pix_acc_list.mean()\n",
    "    print('[V] mIOU={:.3f}, Accuracy={:.3f}'.format(val_m_iou_mean, val_pix_acc_mean))\n",
    "    #tb_writer.add_scalar('val_epoch_m_iou', val_m_iou_mean, epoch)\n",
    "    #tb_writer.add_scalar('val_epoch_pix_acc', val_pix_acc_mean, epoch)\n",
    "    return val_pix_acc_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "600d9790"
   },
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "b74e3dff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.4456: 100%|██████████| 710/710 [04:13<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.5791: 100%|██████████| 710/710 [04:13<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.6024: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.5768: 100%|██████████| 710/710 [04:16<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.6476: 100%|██████████| 710/710 [04:16<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] loss=0.5183, time=1280.1\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19    0.2211   4.5586: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.238, Accuracy=3.077\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.5935: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.5250: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.4665: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.4815: 100%|██████████| 710/710 [04:15<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.6143: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.4940, time=1283.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/19    0.2862   2.6572: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.333, Accuracy=3.098\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.4500: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.5410: 100%|██████████| 710/710 [04:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.5712: 100%|██████████| 710/710 [04:18<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.3920: 100%|██████████| 710/710 [04:16<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.3005: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.4814, time=1286.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/19    0.2244   2.4983: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.407, Accuracy=3.058\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.3686: 100%|██████████| 710/710 [04:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.4784: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.3613: 100%|██████████| 710/710 [04:15<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.5426: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.5413: 100%|██████████| 710/710 [04:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.4673, time=1282.3\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/19    0.4094   3.1345: 100%|█| 1525/1525 [05:09<00:00,  4.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.388, Accuracy=3.115\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.4794: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.3021: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.4169: 100%|██████████| 710/710 [04:15<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.4852: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.3808: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] loss=0.4521, time=1283.3\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/19    0.1581   2.8691: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.377, Accuracy=3.210\n",
      "best fit so far=>saved\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.3968: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.3696: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.4010: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.4881: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.3479: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] loss=0.4465, time=1282.5\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/19    0.3641   2.6224: 100%|█| 1525/1525 [05:09<00:00,  4.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.393, Accuracy=3.136\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.4341: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.3182: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.4597: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.3543: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.5444: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] loss=0.4333, time=1281.1\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/19    0.2766   2.1537: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.412, Accuracy=2.990\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.6334: 100%|██████████| 710/710 [04:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.3750: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.3612: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.6096: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.5746: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] loss=0.4311, time=1283.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/19    0.3757   3.0962: 100%|█| 1525/1525 [05:09<00:00,  4.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.404, Accuracy=3.096\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.4805: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.4558: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.4191: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.6227: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.5512: 100%|██████████| 710/710 [04:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] loss=0.4223, time=1282.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/19    0.4259   2.3448: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.450, Accuracy=3.047\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.3031: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.3913: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.3091: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.4019: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.2458: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] loss=0.4145, time=1283.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/19    0.3836   3.1571: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.396, Accuracy=3.106\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.4415: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.4840: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.3764: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.3449: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.2517: 100%|██████████| 710/710 [04:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss=0.4088, time=1281.5\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/19    0.5100   4.1839: 100%|█| 1525/1525 [05:10<00:00,  4.91it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.411, Accuracy=2.939\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.3125: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.3950: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.3327: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.4920: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.4374: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] loss=0.4033, time=1282.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/19    0.6260   2.8831: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.455, Accuracy=2.916\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.4623: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.3109: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.4654: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.4052: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.4893: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] loss=0.4000, time=1282.9\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/19    0.3409   3.1500: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.423, Accuracy=2.897\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.3351: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.5796: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.4495: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.4256: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.4097: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] loss=0.3915, time=1283.3\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/19    0.5384   3.3112: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.429, Accuracy=3.035\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.3038: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.2838: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.3994: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.1708: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.3901: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] loss=0.3886, time=1282.0\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/19    0.4213   2.2038: 100%|█| 1525/1525 [05:10<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.447, Accuracy=2.951\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.3487: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.5395: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.3672: 100%|██████████| 710/710 [04:15<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.6563: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.3894: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] loss=0.3844, time=1283.7\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/19    0.3957   2.6604: 100%|█| 1525/1525 [05:09<00:00,  4.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.466, Accuracy=3.038\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.5183: 100%|██████████| 710/710 [04:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.3552: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.4399: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.3171: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.4233: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] loss=0.3814, time=1282.7\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/19    0.4418   2.1841: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.478, Accuracy=3.067\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.2603: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.3588: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.3612: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.3082: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.2971: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] loss=0.3740, time=1282.8\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/19    0.2939   2.3230: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.473, Accuracy=3.013\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.4269: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.4029: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.3197: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.3132: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.4827: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] loss=0.3694, time=1283.2\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/19    0.5550   3.0210: 100%|█| 1525/1525 [05:09<00:00,  4.92it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.541, Accuracy=2.960\n",
      "train_dataloader_0\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.4195: 100%|██████████| 710/710 [04:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_1\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.2928: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_2\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.3558: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_3\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.4506: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader_4\n",
      "\n",
      "     Epoch      loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.4464: 100%|██████████| 710/710 [04:15<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] loss=0.3649, time=1282.6\n",
      "\n",
      "  Epoch(V)      mIOU  Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/19    0.3338   2.6426: 100%|█| 1525/1525 [05:10<00:00,  4.92it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V] mIOU=0.462, Accuracy=2.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(global_model, optimizer, clients, val_dataloader, loss_func, epochs, device, patch_size=patch_size, save_path='/app/HSK/FL_Seg/codes/ckpt_FL_du_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8c906b3"
   },
   "source": [
    "### 최고 성능 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1f298c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success\n"
     ]
    }
   ],
   "source": [
    "save_path=os.path.join(workspace_path, 'codes/ckpt_deepv3')\n",
    "\n",
    "checkpoint_path = os.path.join(save_path,'{}_best.pt'.format(model_name))\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "\n",
    "print('model load success')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "baseline-clouds-segmentation-colab-ver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
