{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a28e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import socket\n",
    "# import pickle\n",
    "\n",
    "# while True:\n",
    "#     serverSock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "#     serverSock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "#     serverSock.bind(('', 9007))\n",
    "#     serverSock.listen(1)\n",
    "\n",
    "#     connectionSock, addr = serverSock.accept()\n",
    "\n",
    "#     print(str(addr),'에서 접속이 확인되었습니다.')\n",
    "    \n",
    "#     data = connectionSock.recv(1024)\n",
    "#     cmd = pickle.loads(data)\n",
    "#     print('받은 데이터 : ', cmd)\n",
    "    \n",
    "#     serverSock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972dfacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e227de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_img(x) :\n",
    "  plt.figure()\n",
    "  plt.imshow(x)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2864aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cx_train, cy_train), (cx_test, cy_test) = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")\n",
    "cx_train, cx_test = cx_train/255.0, cx_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2789502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "#    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
    "#    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
    "#    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
    "#    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "#    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
    "#    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "#    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "#    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "#    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "#    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "#    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "#    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "#    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "#    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "#    'worm'\n",
    "# 구글 번역기로 위 내용을 한국어로 번역\n",
    "    '사과', '수족관 물고기', '아기', '곰', '비버', '침대', '꿀벌', '딱정벌레',\n",
    "    '자전거', '병', '그릇', '소년', '다리', '버스', '나비', '낙타',\n",
    "    '캔', '성', '애벌레', '소', '의자', '침팬지', '시계',\n",
    "    '구름','바퀴벌레','소파','게','악어','컵','공룡',\n",
    "    '돌고래', '코끼리', '가자미','숲','여우','소녀','햄스터',\n",
    "    '집', '캥거루', '키보드', '램프', '잔디깎기', '표범', '사자',\n",
    "    '도마뱀', '랍스터', '사람', '매이플트리', '오토바이', '산', '마우스',\n",
    "    '버섯', '오크트리', '오렌지', '난초', '수달', '팜트리', '배',\n",
    "    '픽업트럭', '소나무', '평지', '접시', '양귀비', '호저',\n",
    "    '주머니쥐', '토끼', '너구리', '레이', '도로', '로켓', '장미',\n",
    "    '바다', '인감', '상어', '뒤쥐', '스컹크', '고층건물', '달팽이', '뱀',\n",
    "    '거미', '다람쥐', '전차', '해바라기', '단고추', '테이블',\n",
    "    '탱크', '전화', '텔레비전', '호랑이', '트랙터', '기차', '송어',\n",
    "    '튤립', '거북이', '옷장', '고래', '버드나무', '늑대', '여자',\n",
    "    '벌레'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f17d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "난초\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0,9999)\n",
    "draw_img(cx_test[idx])\n",
    "print(classes[cy_test[idx][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f811816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 30, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 10, 10, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               819712    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,348\n",
      "Trainable params: 936,964\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 00:20:12.990381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 00:20:12.990786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 00:20:12.991147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 00:20:12.991571: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-13 00:20:12.991604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-13 00:20:12.991632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-05-13 00:20:12.991660: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-05-13 00:20:12.991688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-13 00:20:12.991715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-13 00:20:12.991743: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-05-13 00:20:12.991750: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-13 00:20:12.991973: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/user/.local/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32,32,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(100, activation='softmax'))\n",
    "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True) # https://www.tensorflow.org/tutorials/images/segmentation?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0960e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tensorboard/get_started?hl=ko\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "!rm -rf ./logs/\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21314df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 4.0616 - accuracy: 0.0897 - val_loss: 3.3955 - val_accuracy: 0.1850\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 3.3560 - accuracy: 0.1959 - val_loss: 2.9103 - val_accuracy: 0.2798\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 2.9648 - accuracy: 0.2650 - val_loss: 2.6065 - val_accuracy: 0.3344\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 2.7417 - accuracy: 0.3069 - val_loss: 2.4247 - val_accuracy: 0.3718\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 2.5822 - accuracy: 0.3387 - val_loss: 2.5017 - val_accuracy: 0.3588\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 2.4575 - accuracy: 0.3649 - val_loss: 2.2004 - val_accuracy: 0.4224\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 2.3773 - accuracy: 0.3817 - val_loss: 2.1711 - val_accuracy: 0.4295\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 2.2888 - accuracy: 0.4001 - val_loss: 2.2339 - val_accuracy: 0.4229\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.2138 - accuracy: 0.4158 - val_loss: 2.0554 - val_accuracy: 0.4580\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 2.1552 - accuracy: 0.4297 - val_loss: 2.0761 - val_accuracy: 0.4561\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 2.0996 - accuracy: 0.4397 - val_loss: 2.0120 - val_accuracy: 0.4707\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 2.0571 - accuracy: 0.4491 - val_loss: 2.1168 - val_accuracy: 0.4424\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 2.0144 - accuracy: 0.4620 - val_loss: 2.0065 - val_accuracy: 0.4758\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9743 - accuracy: 0.4688 - val_loss: 1.9962 - val_accuracy: 0.4730\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.9348 - accuracy: 0.4761 - val_loss: 1.9646 - val_accuracy: 0.4796\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.9036 - accuracy: 0.4833 - val_loss: 2.1383 - val_accuracy: 0.4449\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8709 - accuracy: 0.4908 - val_loss: 1.9823 - val_accuracy: 0.4762\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.8535 - accuracy: 0.4943 - val_loss: 1.9597 - val_accuracy: 0.4867\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.8164 - accuracy: 0.5006 - val_loss: 2.0076 - val_accuracy: 0.4851\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 1.7822 - accuracy: 0.5062 - val_loss: 1.9260 - val_accuracy: 0.4899\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.7642 - accuracy: 0.5125 - val_loss: 1.9304 - val_accuracy: 0.4913\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.7525 - accuracy: 0.5186 - val_loss: 1.9045 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7175 - accuracy: 0.5218 - val_loss: 1.9281 - val_accuracy: 0.4961\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.7091 - accuracy: 0.5275 - val_loss: 1.9378 - val_accuracy: 0.4904\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.6865 - accuracy: 0.5298 - val_loss: 2.0071 - val_accuracy: 0.4946\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.6638 - accuracy: 0.5337 - val_loss: 1.9439 - val_accuracy: 0.4983\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.6546 - accuracy: 0.5391 - val_loss: 1.9326 - val_accuracy: 0.4896\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.6359 - accuracy: 0.5419 - val_loss: 1.9522 - val_accuracy: 0.4990\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.6118 - accuracy: 0.5477 - val_loss: 1.9523 - val_accuracy: 0.4975\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.6085 - accuracy: 0.5494 - val_loss: 1.9348 - val_accuracy: 0.4997\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 1.5853 - accuracy: 0.5531 - val_loss: 1.9650 - val_accuracy: 0.4837\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.5685 - accuracy: 0.5574 - val_loss: 1.9083 - val_accuracy: 0.4970\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.5534 - accuracy: 0.5619 - val_loss: 2.1079 - val_accuracy: 0.4815\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5531 - accuracy: 0.5647 - val_loss: 1.9505 - val_accuracy: 0.4977\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5454 - accuracy: 0.5639 - val_loss: 1.9818 - val_accuracy: 0.5046\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5369 - accuracy: 0.5634 - val_loss: 1.9279 - val_accuracy: 0.5044\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 1.5210 - accuracy: 0.5673 - val_loss: 1.9205 - val_accuracy: 0.5017\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.5072 - accuracy: 0.5730 - val_loss: 1.9359 - val_accuracy: 0.4922\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.4920 - accuracy: 0.5740 - val_loss: 1.9242 - val_accuracy: 0.4967\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 1.4925 - accuracy: 0.5774 - val_loss: 1.9487 - val_accuracy: 0.4990\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 1.4677 - accuracy: 0.5820 - val_loss: 1.9316 - val_accuracy: 0.5014\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4646 - accuracy: 0.5798 - val_loss: 1.9272 - val_accuracy: 0.4987\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.4669 - accuracy: 0.5805 - val_loss: 1.9070 - val_accuracy: 0.5048\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.4583 - accuracy: 0.5857 - val_loss: 1.9654 - val_accuracy: 0.4959\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.4457 - accuracy: 0.5867 - val_loss: 1.9833 - val_accuracy: 0.4946\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.4390 - accuracy: 0.5886 - val_loss: 1.9369 - val_accuracy: 0.5030\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.4456 - accuracy: 0.5867 - val_loss: 1.9627 - val_accuracy: 0.4984\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.4254 - accuracy: 0.5937 - val_loss: 1.9389 - val_accuracy: 0.4956\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.4262 - accuracy: 0.5941 - val_loss: 1.9360 - val_accuracy: 0.5002\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.4066 - accuracy: 0.5976 - val_loss: 2.0354 - val_accuracy: 0.4975\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.3981 - accuracy: 0.5996 - val_loss: 1.9550 - val_accuracy: 0.5066\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.3950 - accuracy: 0.5991 - val_loss: 1.9656 - val_accuracy: 0.5018\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.3912 - accuracy: 0.6006 - val_loss: 1.9686 - val_accuracy: 0.5109\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3880 - accuracy: 0.6030 - val_loss: 2.0074 - val_accuracy: 0.5165\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3802 - accuracy: 0.6041 - val_loss: 2.0075 - val_accuracy: 0.4992\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.3874 - accuracy: 0.6024 - val_loss: 1.9666 - val_accuracy: 0.5075\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3631 - accuracy: 0.6089 - val_loss: 1.9742 - val_accuracy: 0.5042\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3550 - accuracy: 0.6104 - val_loss: 2.0555 - val_accuracy: 0.5015\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3516 - accuracy: 0.6134 - val_loss: 2.0465 - val_accuracy: 0.5071\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3502 - accuracy: 0.6132 - val_loss: 1.9705 - val_accuracy: 0.5148\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3464 - accuracy: 0.6141 - val_loss: 2.0041 - val_accuracy: 0.5065\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.3379 - accuracy: 0.6143 - val_loss: 1.9643 - val_accuracy: 0.5125\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.3387 - accuracy: 0.6139 - val_loss: 2.0591 - val_accuracy: 0.5082\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.3376 - accuracy: 0.6148 - val_loss: 2.0228 - val_accuracy: 0.5067\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.3266 - accuracy: 0.6168 - val_loss: 1.9961 - val_accuracy: 0.5056\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3258 - accuracy: 0.6169 - val_loss: 1.9424 - val_accuracy: 0.4979\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3164 - accuracy: 0.6181 - val_loss: 1.9968 - val_accuracy: 0.5006\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3090 - accuracy: 0.6228 - val_loss: 1.9257 - val_accuracy: 0.5034\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3111 - accuracy: 0.6213 - val_loss: 2.1759 - val_accuracy: 0.4900\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.3016 - accuracy: 0.6245 - val_loss: 2.0264 - val_accuracy: 0.5046\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.2956 - accuracy: 0.6263 - val_loss: 2.0225 - val_accuracy: 0.5102\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.2869 - accuracy: 0.6267 - val_loss: 2.0078 - val_accuracy: 0.5118\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2814 - accuracy: 0.6297 - val_loss: 2.0215 - val_accuracy: 0.5062\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2915 - accuracy: 0.6247 - val_loss: 1.9780 - val_accuracy: 0.5030\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.2895 - accuracy: 0.6289 - val_loss: 2.0019 - val_accuracy: 0.5093\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2876 - accuracy: 0.6275 - val_loss: 2.0134 - val_accuracy: 0.5048\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.2726 - accuracy: 0.6324 - val_loss: 1.9780 - val_accuracy: 0.4928\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2744 - accuracy: 0.6301 - val_loss: 1.9523 - val_accuracy: 0.5042\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2650 - accuracy: 0.6334 - val_loss: 2.0604 - val_accuracy: 0.5123\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2694 - accuracy: 0.6331 - val_loss: 1.9630 - val_accuracy: 0.5109\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.2608 - accuracy: 0.6328 - val_loss: 2.0399 - val_accuracy: 0.5040\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.2423 - accuracy: 0.6393 - val_loss: 2.0557 - val_accuracy: 0.5146\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.2582 - accuracy: 0.6360 - val_loss: 2.0558 - val_accuracy: 0.5029\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2591 - accuracy: 0.6352 - val_loss: 2.0268 - val_accuracy: 0.4945\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2294 - accuracy: 0.6431 - val_loss: 1.9967 - val_accuracy: 0.5043\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2415 - accuracy: 0.6415 - val_loss: 1.9834 - val_accuracy: 0.4981\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2472 - accuracy: 0.6367 - val_loss: 1.9885 - val_accuracy: 0.5003\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2268 - accuracy: 0.6436 - val_loss: 2.0188 - val_accuracy: 0.5091\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.2240 - accuracy: 0.6439 - val_loss: 1.9967 - val_accuracy: 0.5010\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2183 - accuracy: 0.6433 - val_loss: 2.0374 - val_accuracy: 0.5102\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2214 - accuracy: 0.6482 - val_loss: 2.0042 - val_accuracy: 0.4986\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.2265 - accuracy: 0.6433 - val_loss: 2.1194 - val_accuracy: 0.4948\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2202 - accuracy: 0.6486 - val_loss: 2.0940 - val_accuracy: 0.5107\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1994 - accuracy: 0.6520 - val_loss: 2.0068 - val_accuracy: 0.5038\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2155 - accuracy: 0.6475 - val_loss: 2.1052 - val_accuracy: 0.4872\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2082 - accuracy: 0.6475 - val_loss: 2.0229 - val_accuracy: 0.4976\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2016 - accuracy: 0.6495 - val_loss: 2.0352 - val_accuracy: 0.4934\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1972 - accuracy: 0.6515 - val_loss: 2.0369 - val_accuracy: 0.4918\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2031 - accuracy: 0.6526 - val_loss: 2.0842 - val_accuracy: 0.5046\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.2032 - accuracy: 0.6520 - val_loss: 2.0309 - val_accuracy: 0.5017\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(cx_train, cy_train, epochs=5)\n",
    "# for tensorboard\n",
    "history = model.fit(cx_train, cy_train, epochs=100, validation_data=(cx_test, cy_test), callbacks=[tensorboard_callback])\n",
    "# 모델 저장, 훈련 후 다운로드를 받아두어야 나중에 업로드하여 재사용 가능함.\n",
    "model.save(\"cifar100.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
